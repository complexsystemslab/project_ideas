
 
# M.Phil projects ideas 

Soumya Banerjee 

University of Cambridge, Cambridge, United Kingdom 
∗ E-mail: sb2333@cam.ac.uk 

## Projects 

* Contemporary approaches towards explainable AI are model-centric. We will use data-centric approaches to explain the complex interplay between data and models. This will build on published work [1]. This project will be ideal for a student with interest in machine learning and who has coding experience. The work will lead to publication in a good journal and open source tools. This will help the student in either PhD applications or work in industry. The student will also learn how to work in a different field and learn skills needed for inter-disciplinary research. The student may also have an opportunity to interact with other experts in machine learning and healthcare. 

This work is part of the Accelerate Programme for Scientific Discovery which aims to democratize access to AI tools and apply AI to problems from diverse disciplines. The student will be part of a growing community of inter-disciplinary AI researchers at the University of Cambridge. 

* For high stakes decisions we need simple and explainable/interpretable models. This need is acute in the case of healthcare and social sciences like recidivism prediction [2]. In this project, we will build simple interpretable models that are surrogates for deep learning models. We will show how to do this in the context of data for severe mental illness. 

The student will look at publicly available data and synthetic data to generate surrogate models that are transparent and interpretable. The process of creating these surrogate interpretable models will be automated. This can also be partially based on published work [1]. 

The surrogate models can be decision trees (like CART) trained on the input and output of a deep learning model [1]. This can use R packages like party, rpart, partykit or other packages. 
This will lead to tools that automated the creation of surrogate interpretable models based on deep learning models in healthcare. 

This project will be ideal for a student with interest in machine learning and who has coding
experience. The work will lead to publication in a high impact journal and open source tools. This will help the student in either PhD applications or work in industry. The student will also learn how to work in a different field and learn skills needed for inter-disciplinary research. The student will also have an opportunity to interact with experts in machine learning and healthcare. 

This work is part of the Accelerate Programme for Scientific Discovery which aims to democratize access to AI tools and apply AI to problems from diverse disciplines. The student will be part of a growing community of inter-disciplinary AI researchers. 

* Other project ideas are generating synthetic data from private datasets like data from electronic healthcare records data [3], other explanatory artificial intelligence (xAI) techniques, privacy preserving machine learning [4], documenting data and models, detecting concept drift, etc. 

Other project ideas can be developed according to student interests. 

## Contact

Please contact Soumya Banerjee at sb2333@cam.ac.uk to have an informal chat. 

You can learn more about my work here: 
https://sites.google.com/site/neelsoumya 


## References 

1. Banerjee S, Lio P, Jones PB, Cardinal RN (2021) A class-contrastive human-interpretable machine learning approach to predict mortality in severe mental illness. npj Schizophr 7: 1–13. 

2. Rudin C (2019) Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead. Nat Mach Intell 1: 206–215. 

3. Banerjee S, tom rp Bishop (2022) dsSynthetic: Synthetic data generation for the DataSHIELD federated analysis system. BMC Res Notes 15: 230. 

4. Banerjee S, Sofack GN, Papakonstantinou T, Avraam D, Burton P, et al. (2022) dsSurvival: Privacy preserving survival models for federated individual patient meta-analysis in DataSHIELD. BMC Res Notes 15: 197.
